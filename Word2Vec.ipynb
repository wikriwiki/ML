#코랩 환경입니다. CPU사용
from google.colab import drive

# 📂 드라이브 마운트
drive.mount('/content/drive') #--->자기 구글 드라이브로 수정


!pip uninstall -y numpy scipy
!pip install numpy==1.24.4 scipy==1.10.1 gensim==4.3.3
# 실행후 뜨는창 무시하고 아래 코드 실행


#---------------------------------------------------------------
import pandas as pd
import numpy as np
from gensim.models import Word2Vec

# 1단계: CSV 파일 로드
df = pd.read_csv("/content/drive/MyDrive/movie/final_boxoffice.csv")

# 2단계: 배우 리스트 전처리 (파이프 '|' 기준 분리 및 공백 제거)
df['actor_list'] = df['actors'].fillna("").apply(lambda x: [a.strip() for a in x.split('|') if a.strip()])

# 3단계: Word2Vec 학습용 데이터 구성 및 모델 훈련
actor_sentences = df['actor_list'].tolist()

model = Word2Vec(
    sentences=actor_sentences,
    vector_size=8,      # 임베딩 차원 수 ----> 늘릴수록 표현력이 커지고 과적합 여지가 있지만 늘리는게 관계성을 볼때 효과적이였음 64까지 늘려봄
    window=3,           # 문맥 윈도우 크기  --------------> 좌우로 몇개까지의 단어를 문맥으로 볼건지에 대한 부분 2로도 충분
    min_count=2,        # 최소 등장 횟수 필터링  ---------------> 등장수가 1번 이하면 학습에 참여가 안됌
    sg=1,               # skip-gram (1) vs CBOW (0)  ---------->  sg=1: Skip-Gram, sg=0: CBOW (Continuous Bag of Words) 1로 했을때 저는 잘됨
                        # Skip-Gram ->중심 단어로 주변 단어를 예측함 , CBOW (Continuous Bag of Words) ->주변 단어들로 중심 단어를 예측.
    epochs=30,          # 에포크를 늘려가며 학습시키면 점점 외국인 이름이 사라져간다... 효과는 있었다  .
    negative=10,        # negative sampling 개수
    seed=42
)

print("✅ Word2Vec 임베딩 학습 완료")
#--------------------------------------------------------------------




#관계성 예측 코드
def get_similar_actors(actor_name, model, topn=10):
    try:
        similar_actors = model.wv.most_similar(actor_name, topn=topn)
        print(f"✅ '{actor_name}'와 유사한 배우 Top {topn}:")
        for i, (name, score) in enumerate(similar_actors, 1):
            print(f"{i}. {name} (유사도: {score:.4f})")
        return similar_actors
    except KeyError:
        print(f"❌ '{actor_name}'는 학습된 모델에 없습니다.")
        return []



get_similar_actors("마동석", model)


#모델 학습에 사용된 배우수 출력
print("✅ 실제 학습된 배우 수:", len(model.wv.index_to_key))
print("🎞️ 평균 배우 수 (배우 리스트 길이):", np.mean([len(s) for s in actor_sentences]))

